{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import glob \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The glob module helps to take multiple inputs from a directory \n",
    "path_short=glob.glob(\"short_length/*.jpg\") \n",
    "# it takes all the images as an input from the short_length directory. \n",
    "#You should change the directory while working with your own pc.\n",
    "path_long=glob.glob(\"long_length/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_short={} # dictionary for saving multiple images within it's key. \n",
    "dic_long={}\n",
    "for img in path_short:\n",
    "    dic_short[img]=cv2.imread(img)\n",
    "    \n",
    "for img in path_long:\n",
    "    dic_long[img]=cv2.imread(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "#function fore resizing the images \n",
    "def resize_and_show(name, image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    cv2.imshow(name,img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "#preview the images\n",
    "# if you are in jupyter notebook the images wil open in a new window \n",
    "# image frame name and image name is same \n",
    "for name, image in dic_short.items():  \n",
    "    resize_and_show(name, image) \n",
    "\n",
    "for name, image in dic_long.items():\n",
    "    resize_and_show(name,image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above cell images will show in a new window as like as below with a image frame **1.jpg**.  <img src=\"short_length/1.jpg\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short length 2nd image with image frame **2.jpg**<img src=\"short_length/2.jpg\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full/long length 2nd image with image frame **1 .jpg**<img src=\"long_length/1 .jpg\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full/long length 2nd image with image frame **2 .jpg**<img src=\"long_length/2 .jpg\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B:** You can also use matplotlib library to show the image within the notebook. For doing so use **plt.imshow()** insead of **cv2.imshow()** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "# MediaPipe solution API\n",
    "mp_face_detection = mp.solutions.face_detection # creating a face detection object of mediapipe solution API\n",
    "\n",
    "help(mp_face_detection.FaceDetection)  # Documentation of the face detection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DrawingSpec for drawing the face landmarks later.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MediaPipe Face Detection with short range model.\n",
    "\n",
    "with mp_face_detection.FaceDetection(min_detection_confidence=0.5,model_selection=0) as face_detection:\n",
    "    for name, image in dic_short.items():\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        if not results.detections:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(annotated_image, detection)\n",
    "            resize_and_show(name,annotated_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the above cell, you will find the figures as follows. <img src=\"Detect 1.PNG\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Detect 2.PNG\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**N.B:** The images will be showen one after another. If you click on the exit sign of the upper right corner of any popup window then another image will be shown.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MediaPipe Face Detection with full range model.\n",
    "\n",
    "with mp_face_detection.FaceDetection(min_detection_confidence=0.5,model_selection=1) as face_detection:\n",
    "    for name, image in dic_long.items():\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        if not results.detections:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(annotated_image, detection)\n",
    "        resize_and_show(name,annotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the above cell, you will find the figures as follows. <img src=\"Detect 3.PNG\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Detect 4.PNG\" width=480 height=480 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
